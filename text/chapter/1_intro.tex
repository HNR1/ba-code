\section{Introduction}
Diffusion models are part of the the latest advancements in computer vision and are used for tasks involving image enhancement, completion, denoising, and restoration, but most notably image synthesis. Popular generative models include DALL-E 2 \cite{ramesh2022hierarchical}, \href{https://www.midjourney.com}{Midjourney} and \textbf{Stable Diffusion} (SD), with the latter offering free access to this kind of image generation software.\\
A big challenge for these generative models remains the computational intensity when image sizes increase. The computational demands square with the number of pixels (and tokens), due to the models reliance on a transformer backbone.\\
A promising remedy for this issue is the concept of Token Merging (ToMe) by \cite{bolya2023tomesd}. ToMe for SD exploits redundancies in the input by reducing by merging similar tokens to reduce the number of tokens to be processed by the transformer. Unlike token pruning methods, ToMe retains the original image size by unmerging the tokens after they were processed by a computational unit. Additionally, ToMe is model agnostic and requires no specific training. The authors claim: "ToMe for Stable Diffusion minimally impacts visual quality while offering up to $2 \times$ faster evaluation using $5.6 \times$ less memory" \cite{bolya2023tomesd}. ToMe for SD is an extension of a the original version of ToMe \cite{bolya2023tome}, which more broadly tried to speed up Vision Transformer models \cite{dosovitskiy2020image}.\\
In this work, our goal is to replicate parts of their findings, while also investigating different configurations of ToMe and their effect on SD's performance in image generation tasks. Our setup involves creating datasets of images with and without ToMe and calculating their Fr√©chet-Inception-Distance to assess the images similarity while also measuring the algorithms speed.\\
The main contents of this thesis are spread across four sections. Section \ref{backgorund} will provide you with explanations for important concepts related to our studies. An overview of alternative approaches to solving diffusion model's inefficiency problem is presented in Section \ref{related_work}. Section \ref{token_merging} holds an in-depth overview of the functionality of ToMe, explicitly laying out the merge and unmerge process. Finally, Section \ref{experiments} explains the whole experimental process this thesis is built upon, describing in detail the setup and the results of our trials.\\
We will show that ToMe is indeed able to cut image generation time in half while preserving most of the information, thus producing images very close to the original. Moreover, we will show how altering the configuration of ToMe can further improve image quality, as well as speed (albeit marginally). We hope that our results can validate the legitimacy of ToMe and motivate further research.\\


