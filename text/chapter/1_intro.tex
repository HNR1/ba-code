\section{Introduction}
Diffusion models are part of the the latest advancements in computer vision and are used for tasks involving image enhancement, completion, denoising, and restoration, but most notably image synthesis. Popular generative models include DALL-E 2 \cite{ramesh2022hierarchical}, \href{https://www.midjourney.com}{Midjourney} and \textbf{Stable Diffusion} (SD), with the latter offering free access to this kind of image generation software.\\
A big challenge for these generative models remains the computational intensity when image sizes increase. The computational demands square with the number of pixels (and tokens), due to the models reliance on a transformer backbone.\\
A promising remedy for this issue is the concept of Token Merging (ToMe) by \cite{bolya2023tomesd}. ToMe for SD reduces the number of processed tokens within the transformer by merging the similar tokens. Unlike token pruning methods, ToMe retains the original image size by unmerging the tokens after they were processed by a computational unit. Additionally, ToMe is model agnostic and requires no specific training. The authors claim: "ToMe for Stable Diffusion minimally impacts visual quality while offering up to $2 \times$ faster evaluation using $5.6 \times$ less memory" \cite{bolya2023tomesd}.\\
In this work, our goal is to replicate parts of their findings while also investigating different configurations of ToMe and their effect on SD's performance in image generation tasks. Our setup involves creating datasets of images with and without ToMe and calculating their Fr√©chet-Inception-Distance to assess the images similarity while also measuring the algorithms speed.\\
The main contents of this thesis are spread across four sections. Section \ref{backgorund} will provide you with explanations for important concepts related to our studies. An overview of alternative approaches to solving diffusion model's inefficiency problem is presented in Section \ref{related_work}. Section \ref{token_merging} gives a theoretical overview over the functionality of the ToMe algorithm.
\\
We will show that ToMe is indeed able to cut image generation time in half while preserving most of the information, thus producing images very close to the original. Moreover, we will show how altering the configuration of ToMe can further improve image quality, as well as speed (albeit marginally).
\\


