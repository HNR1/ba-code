\section{Experimental procedures}
We perform several experiments using the model "stable-diffusion-v1-5" by runwayml\cite{Rombach_2022_CVPR} and applying different kinds of token merging to a set of prompts and measuring the performance.
The performance is defined by\\ 
\(1)\) speed: the average diffusion time for every image of the set and\\
\(2)\) image quality: the FID-value between sets of images that had token merging applied and their counterparts (that is same prompt, seed and image size) that didn't use any token merging.

\subsection{Setup}
\subsubsection*{Software}
The first iteration of the experiment was to compare how diffusion time and image quality change across a spectrum of different volume of tokens  removed while token merging is applied in different layers of the transformer (self-attention, cross-attention and mlp).\\
The images were generated with a "DiffusionPipeline" from HuggingFace's diffusers library using the "stable-diffusion-v1-5" model\cite{Rombach_2022_CVPR}.\\
We sampled a set of \(n=500\) prompts from the dataset "Gustavosta/Stable-Diffusion-Prompts" on HuggingFace which has 80,000 prompts filtered and extracted from the image finder for Stable Diffusion: "Lexica.art".\\
Seven $768 \times 768$ images were created per prompt, with a 0\%, 10\%, 20\%, 30\%, 40\%, 50\% and 60\% merge applied respectively, creating a set of 3,500 images which can be split up into 7 subsets of 500 images each for every merge volume.\\
This experiment was run multiple times with the merges applied in different layers of the transformer to compare performance.
--Logs were created--

\subsubsection*{Hardware}
All experminents were conducted on Nvidida GeForce GTX 1080 Ti GPUs. Individual images were always created on single GPUs.
--images and logs on 1080ti--

\subsection{Adjustments}
\subsubsection*{FID}
We created and used our own fork of pytorch-fid\cite{Seitzer2020FID} to accommodate for the hpc not being connected to the internet and therefore not being able to download the weights of the Inception model to calculate FID-values. Our fork loads these weights from a local directory to avoid any connection to the internet and requires the user to have them pre-installed.

\subsubsection*{Prompts}
We shortened every prompt thats exceeds 300 characters in order to reduce the number of tokens to a maximum of 77, as CLIP\cite{radford2021learning} can only handle up to 77 tokens.\\
This is done by determining the index (\(idx\)) of the last comma in the first 300 characters of every prompt and then cutting off everything from this point onwards.
\begin{lstlisting}[language=Python]
prompt = prompt[:idx]
\end{lstlisting}

\subsection{Comparison to original setup}
Text.

\subsection{Results}
\subsubsection*{1): Exploring different components of the transformer}
Firstly, we are comparing the sets of $768 \times 768$ images with ToMe applied in different components of the transformer (self-attn, cross-attn and mlp). Each set contains 3,500 images (500 per merge volume).

\newpage
\subsubsection*{1.1): default (only self-attn) vs all (self-attn, cross-attn and mlp)}
%\begin{figure}
%   \input{plots/plot1_fid}
%   \input{plots/plot1_time}
%\end{figure}
\input{tables/table1}
Test1

\newpage
\begin{figure}
    \input{plots/plot2_fid}
    \input{plots/plot2_time}
    \input{plots/plot5_fid}
    \input{plots/plot5_time}
\end{figure}
\subsubsection*{1.2): default vs self-attn \& cross-attn vs self-attn \& mlp}
Test1

\subsubsection*{1.3): default vs cross-attn \& mlp vs only cross-attn}
Test1

\newpage
\begin{figure}
    \input{plots/plot3_fid}
    \input{plots/plot3_time}
\end{figure}
\subsubsection*{1.4): default vs self-attn \& cross-attn (the second time)}
Test1

\newpage
\begin{figure}
    \input{plots/plot4_fid}
    \input{plots/plot4_time}
\end{figure}
\subsubsection*{2): Exploring different images sizes}
Text.
\subsubsection*{2.1): Moving to smaller images}
Test1

\newpage
\subsubsection*{2.2): Moving to larger images}
Test1

\newpage
\begin{figure}
    \input{plots/plot6_fid}
    \input{plots/plot6_time}
\end{figure}
\subsubsection*{3): Exploring different strides}
Text.
\subsubsection*{3.1): 3x3 stride}
Test1
\subsubsection*{3.2): 1x2 horizontal stride}
\begin{align*}
    r_{max} = 1-\frac{1}{1*2} = 0.5
\end{align*}

\newpage
\subsection{Comparison to original results}
Text.