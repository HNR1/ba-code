\section{Token Merging}
In Token Merging for Stable Diffusion\cite{bolya2023tomesd} the number of tokens is reduced by r\% by merging similar tokens before every diffusion step and unmerging them after to retain the original size of the image.\\ The tokens are partitioned into a source (src) and a destination (dst) set and the most similar tokens from the src set are continously merged into their dst counterparts until the number of tokens has reduced by \(r\)\%, with \(r\) being a hyperparameter determined by the user.\\ The choice of \(r\) is a trade-off between image fidelity and diffusion time as a lower amount of tokens requires a smaller computation time but more information about the image is lost in the merge process.\\
The default setup of tomesd\cite{bolya2023tomesd} only applies merging to the self-attention layer in the transformer.

\subsection{Merge and Unmerge algorithms}
\subsubsection*{Merging.} The Merge algorithm uses Bipartite-Soft-Matching to determine the similarity of tokens between the src and dst set. The two most similar tokens are taken and merged into a new token until the overall number of tokens has reduced by \(r\)\%.\\
Two tokens with \(c\) channels \(x_1, x_2 \in \mathbb{R}^c\) would be merged into a new token \(x_{1,2}^* \in \mathbb{R}^c \) by averaging it's features, e.g. \[x_{1,2}^* = \frac{x_1 + x_2}{2}\]

\subsubsection*{Unmerging.} The Unmerge algorithm takes an originally merged token $x_{1,2}^* \in \mathbb{R}^c$ and splits it up into its original tokens $x_1', x_2' \in \mathbb{R}^c$, e.g. 
\begin{align*}
    x_1' = x_{1,2}^* \quad\quad
    x_2' = x_{1,2}^*
\end{align*}
in order to recreate the pre-merge amount of tokens.\\
This naive approach does lose information because the now unmerged tokens both have the average of their previous values, but this loss is small due their already high similarity before the merge.\\ Further exploration might yield improvements here.

\subsection{Bipartite-Soft-Matching}
Text.

\subsection{Token similarity}
Similarity between tokens is \(not\) intuitively defined by the distance between their features, because the feature space in transformers is  overparameterized.

\subsection{Different approaches}
Text.

